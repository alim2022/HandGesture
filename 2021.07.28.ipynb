{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "622d5569",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import\n",
    "import matplotlib.pyplot as plt\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import cv2\n",
    "from IPython.display import clear_output\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a8701f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#instantiate drawing & hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_hands = mp.solutions.hands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c35e7337",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"dataset.pkl\", \"rb\") as f:\n",
    "    dataset = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3fdb30a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0524134d",
   "metadata": {},
   "source": [
    "1. one = 0\n",
    "2. two = 1\n",
    "3. three = 2\n",
    "4. thumb = 3\n",
    "5. fist = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "41cf7579",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "cnt_data = np.zeros(5)\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "hands = mp_hands.Hands(static_image_mode=False , max_num_hands = 1 , min_detection_confidence=0.7, min_tracking_confidence=0.5)\n",
    "\n",
    "while cap.isOpened():\n",
    "    success, img = cap.read()\n",
    "    if not success:\n",
    "        print(\"image fetch fail\")\n",
    "        continue\n",
    "        \n",
    "    img = cv2.flip(img, 1)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img.flags.writeable = False\n",
    "    results = hands.process(img)\n",
    "    img.flags.writeable = True\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "    \n",
    "    if results.multi_hand_landmarks is not None:\n",
    "        hand_landmarks = results.multi_hand_landmarks[0]\n",
    "        mp_drawing.draw_landmarks(img, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "    \n",
    "    strs = \"\"\n",
    "    for cnt in cnt_data:\n",
    "        strs += f\"{int(cnt):02d} \" \n",
    "    cv2.putText(img, strs , (50,50) , cv2.FONT_HERSHEY_COMPLEX, 1, (255,255,255))\n",
    "    \n",
    "    cv2.imshow(\"img\",img)\n",
    "    key_value = cv2.waitKey(5)\n",
    "    \n",
    "    if key_value == 27:\n",
    "        break\n",
    "        \n",
    "    if key_value==49:\n",
    "        data_pair = [hand_landmarks, 0]\n",
    "        dataset.append(data_pair)\n",
    "        cnt_data[0]+=1\n",
    "    elif key_value==50:\n",
    "        data_pair = [hand_landmarks, 1]\n",
    "        dataset.append(data_pair)\n",
    "        cnt_data[1]+=1\n",
    "    elif key_value==51:\n",
    "        data_pair = [hand_landmarks, 2]\n",
    "        dataset.append(data_pair)\n",
    "        cnt_data[2]+=1\n",
    "    elif key_value==52:\n",
    "        data_pair = [hand_landmarks, 3]\n",
    "        dataset.append(data_pair)\n",
    "        cnt_data[3]+=1\n",
    "    elif key_value==53:\n",
    "        data_pair = [hand_landmarks, 4]\n",
    "        dataset.append(data_pair)\n",
    "        cnt_data[4]+=1\n",
    "    elif key_value==27:\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4671a69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#determine\n",
    "def simple_classification(hand_landmarks):\n",
    "    finger_up = [False, False, False, False, False]\n",
    "    \n",
    "    if(hand_landmarks.landmark[4].y < hand_landmarks.landmark[3].y\n",
    "       and hand_landmarks.landmark[3].y < hand_landmarks.landmark[2].y\n",
    "       and hand_landmarks.landmark[2].y < hand_landmarks.landmark[1].y\n",
    "       and hand_landmarks.landmark[1].y < hand_landmarks.landmark[0].y\n",
    "       and hand_landmarks.landmark[3].y < hand_landmarks.landmark[6].y \n",
    "      ):\n",
    "        finger_up[0] = True\n",
    "    if(hand_landmarks.landmark[8].y < hand_landmarks.landmark[7].y\n",
    "       and hand_landmarks.landmark[7].y < hand_landmarks.landmark[6].y\n",
    "       and hand_landmarks.landmark[6].y < hand_landmarks.landmark[5].y\n",
    "       and hand_landmarks.landmark[5].y < hand_landmarks.landmark[0].y\n",
    "      ):\n",
    "        finger_up[1] = True\n",
    "    if(hand_landmarks.landmark[12].y < hand_landmarks.landmark[11].y\n",
    "       and hand_landmarks.landmark[11].y < hand_landmarks.landmark[10].y\n",
    "       and hand_landmarks.landmark[10].y < hand_landmarks.landmark[9].y\n",
    "       and hand_landmarks.landmark[9].y < hand_landmarks.landmark[0].y\\\n",
    "      ):\n",
    "        finger_up[2] = True\n",
    "    if(hand_landmarks.landmark[16].y < hand_landmarks.landmark[15].y\n",
    "       and hand_landmarks.landmark[15].y < hand_landmarks.landmark[14].y\n",
    "       and hand_landmarks.landmark[14].y < hand_landmarks.landmark[13].y\n",
    "       and hand_landmarks.landmark[13].y < hand_landmarks.landmark[0].y\n",
    "      ):\n",
    "        finger_up[3] = True\n",
    "    if(hand_landmarks.landmark[20].y < hand_landmarks.landmark[19].y \n",
    "       and hand_landmarks.landmark[19].y < hand_landmarks.landmark[18].y \n",
    "       and hand_landmarks.landmark[18].y < hand_landmarks.landmark[17].y\n",
    "       and hand_landmarks.landmark[17].y < hand_landmarks.landmark[0].y\n",
    "      ):\n",
    "        finger_up[4] = True\n",
    "    \n",
    "    #print(finger_up)\n",
    "    \n",
    "    if(finger_up[1] and not finger_up[2] and not finger_up[3] and not finger_up[4]):\n",
    "        return 0\n",
    "    elif(finger_up[1] and finger_up[2] and not finger_up[3] and not finger_up[4]):\n",
    "        return 1\n",
    "    elif(finger_up[1] and finger_up[2] and finger_up[3] and not finger_up[4]):\n",
    "        return 2\n",
    "    elif(finger_up[0] and not finger_up[1] and not finger_up[2] and not finger_up[3] and not finger_up[4]):\n",
    "        return 3\n",
    "    else:\n",
    "        return 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "163a9159",
   "metadata": {},
   "outputs": [],
   "source": [
    "hand_landmarks, true_class = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "87fd1d47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n"
     ]
    }
   ],
   "source": [
    "predict_class = simple_classification(hand_landmarks)\n",
    "print(predict_class, true_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b136875b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 96.0 %\n"
     ]
    }
   ],
   "source": [
    "correct_cnt = 0\n",
    "total_cnt = 0\n",
    "for data in dataset:\n",
    "    hand_landmarks, true_class = data\n",
    "    predict_class = simple_classification(hand_landmarks)\n",
    "    if (predict_class == true_class):\n",
    "        correct_cnt +=1\n",
    "    total_cnt+=1\n",
    "print(f\"accuracy : {correct_cnt * 100/total_cnt} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "00d5ec45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10.  0.  0.  0.  0.]\n",
      " [ 0. 10.  0.  0.  0.]\n",
      " [ 0.  0.  9.  0.  1.]\n",
      " [ 0.  0.  0.  9.  1.]\n",
      " [ 0.  0.  0.  0. 10.]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# confusion matrix\n",
    "confusion_matrix = np.zeros((5,5))\n",
    "for data in dataset:\n",
    "    hand_landmarks, true_class = data\n",
    "    predict_class = simple_classification(hand_landmarks)\n",
    "    confusion_matrix[true_class, predict_class] +=1\n",
    "print(confusion_matrix)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(confusion_matrix)\n",
    "ax.set_title(\"confusion matrix\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22d92c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# complex method\n",
    "new_dataset = []\n",
    "for data in dataset:\n",
    "    hand_landmarks, true_class = data\n",
    "\n",
    "    adjacency_list = [\n",
    "        [0,1,2],[1,2,3],[2,3,4],[0,5,6],[5,6,7],[6,7,8],\n",
    "        [0,9,10],[9,10,11],[10,11,12],[0,13,14],[13,14,15],\n",
    "        [14,15,16],[0,17,18],[17,18,19],[18,19,20]\n",
    "    ]\n",
    "\n",
    "    angle_list=[]\n",
    "\n",
    "    for adjacency in adjacency_list :\n",
    "        idx0, idx1, idx2 = adjacency\n",
    "        point0 = np.array([hand_landmarks.landmark[idx0].x, hand_landmarks.landmark[idx0].y, hand_landmarks.landmark[idx0].z])\n",
    "        point1 = np.array([hand_landmarks.landmark[idx1].x, hand_landmarks.landmark[idx1].y, hand_landmarks.landmark[idx1].z])\n",
    "        point2 = np.array([hand_landmarks.landmark[idx2].x, hand_landmarks.landmark[idx2].y, hand_landmarks.landmark[idx2].z])\n",
    "\n",
    "        vector0 = point0 - point1\n",
    "        vector1 = point2 - point1\n",
    "        inner_product_result = np.dot(vector0,vector1)\n",
    "        cos_theta = inner_product_result/(np.linalg.norm(vector0) * np.linalg.norm(vector1))\n",
    "        theta = np.arccos(cos_theta)\n",
    "        angle_list.append(theta)\n",
    "    \n",
    "    new_dataset.append([angle_list, true_class])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6c54fcee",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"new_dataset.pkl\", \"wb\")as f:\n",
    "    pickle.dump(new_dataset,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7ed0759",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b052467",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = KNeighborsClassifier(n_neighbors=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c3778e15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_inputs = []\n",
    "training_labels = []\n",
    "for data in new_dataset:\n",
    "    angle_list, true_class = data\n",
    "    training_inputs.append(angle_list)\n",
    "    training_labels.append(true_class)\n",
    "classifier.fit(training_inputs, training_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9bdbd806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(n_neighbors=3)\n"
     ]
    }
   ],
   "source": [
    "print(classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "515a05df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4,\n",
       "       4, 4, 4, 4, 4, 4])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.predict(training_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bc368151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 98.0 %\n"
     ]
    }
   ],
   "source": [
    "correct_cnt = 0\n",
    "total_cnt = 0\n",
    "for data in new_dataset:\n",
    "    angle_list, true_class = data\n",
    "    predict_class = classifier.predict([angle_list])[0]\n",
    "    if (predict_class == true_class):\n",
    "        correct_cnt +=1\n",
    "    total_cnt+=1\n",
    "print(f\"accuracy : {correct_cnt * 100/total_cnt} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a2929947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10.  0.  0.  0.  0.]\n",
      " [ 0. 10.  0.  0.  0.]\n",
      " [ 0.  0. 10.  0.  0.]\n",
      " [ 0.  0.  1.  9.  0.]\n",
      " [ 0.  0.  0.  0. 10.]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# confusion matrix\n",
    "confusion_matrix = np.zeros((5,5))\n",
    "for data in new_dataset:\n",
    "    angle_list, true_class = data\n",
    "    predict_class = classifier.predict([angle_list])[0]\n",
    "    confusion_matrix[true_class, predict_class] +=1\n",
    "print(confusion_matrix)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(confusion_matrix)\n",
    "ax.set_title(\"confusion matrix\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9747c09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seperate training data & test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "56854afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HandGesture:\n",
    "    def __init__(self):\n",
    "        self.classifier = KNeighborsClassifier(n_neighbors=3)\n",
    "        \n",
    "        with open(\"new_dataset.pkl\",\"rb\") as f:\n",
    "            dataset = pickle.load(f)\n",
    "        training_inputs = []\n",
    "        training_labels = []\n",
    "        for data in new_dataset:\n",
    "            angle_list, true_class = data\n",
    "            training_inputs.append(angle_list)\n",
    "            training_labels.append(true_class)\n",
    "        self.classifier.fit(training_inputs, training_labels)\n",
    "    \n",
    "    def get_prediction(self, hand_landmarks):\n",
    "        adjacency_list = [\n",
    "            [0,1,2],[1,2,3],[2,3,4],[0,5,6],[5,6,7],[6,7,8],\n",
    "            [0,9,10],[9,10,11],[10,11,12],[0,13,14],[13,14,15],\n",
    "            [14,15,16],[0,17,18],[17,18,19],[18,19,20]\n",
    "        ]\n",
    "\n",
    "        angle_list=[]\n",
    "\n",
    "        for adjacency in adjacency_list :\n",
    "            idx0, idx1, idx2 = adjacency\n",
    "            point0 = np.array([hand_landmarks.landmark[idx0].x, hand_landmarks.landmark[idx0].y, hand_landmarks.landmark[idx0].z])\n",
    "            point1 = np.array([hand_landmarks.landmark[idx1].x, hand_landmarks.landmark[idx1].y, hand_landmarks.landmark[idx1].z])\n",
    "            point2 = np.array([hand_landmarks.landmark[idx2].x, hand_landmarks.landmark[idx2].y, hand_landmarks.landmark[idx2].z])\n",
    "\n",
    "            vector0 = point0 - point1\n",
    "            vector1 = point2 - point1\n",
    "            inner_product_result = np.dot(vector0,vector1)\n",
    "            cos_theta = inner_product_result/(np.linalg.norm(vector0) * np.linalg.norm(vector1))\n",
    "            theta = np.arccos(cos_theta)\n",
    "            angle_list.append(theta)\n",
    "            \n",
    "        return self.classifier.predict([angle_list])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1418a681",
   "metadata": {},
   "outputs": [],
   "source": [
    "hand_gesture = HandGesture()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a04c8aac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n"
     ]
    }
   ],
   "source": [
    "hand_landmarks, true_class = dataset[0]\n",
    "predict_class = hand_gesture.get_prediction(hand_landmarks)\n",
    "print(predict_class, true_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86fa81c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
